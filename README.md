深Wiki 系统研发调研报告
项目背景与目标
DeepWiki 类似系统旨在帮助开发者高效理解大型代码仓库，自动生成结构化的文档和架构图，并提供基于自然语言的问答功能
medium.com
。核心目标包括：解析仓库结构（文件树、模块依赖、函数/类调用关系等）、生成项目文档页面和架构图，以及支持对仓库内容的自然语言问答。 下文将围绕这些目标，调研可用的开源工具与框架，提出技术栈方案，分析类似项目示例，并给出系统架构设计建议，最后附上关键功能的示例代码。
可用的开源工具与框架
实现 DeepWiki 系统需要涉及代码解析、图形可视化和自然语言问答三方面的技术。下面按类别列出相关的开源工具与框架：
代码解析与静态分析：
Tree-sitter： 一种多语言支持的通用解析库，可为源码构建抽象语法树（AST），并且支持高效的增量解析
tree-sitter.github.io
。Tree-sitter 已有多种语言的解析器，可用于提取函数定义、调用和依赖关系等结构信息。
语言服务器协议（LSP）： 利用各语言的 LSP 实现进行代码解析。比如 Crabviz 工具基于 LSP 获取不同语言的符号和引用信息，从而生成跨语言的函数调用关系图
reddit.com
。借助 LSP，我们可以通过各语言的语言服务器来查询函数被调用关系、类的引用等。
AST 分析库： 对特定语言，可直接使用AST解析库或静态分析工具。例如 Python 内置 ast 模块适合解析Python代码，提取函数调用和类继承关系等
medium.com
；Java 可使用 Eclipse JDT 或 Spoon 等解析框架；JavaScript 可采用 Babel 提供的 AST 工具。配合静态分析工具（如 pylint、mypy 的AST分析，或 CodeQL 查询）可以获取更深入的依赖关系。
代码标签和查询： 工具如 Universal Ctags 可以扫描代码生成符号索引，对于简单的跨文件调用关系，可结合 grep 或自定义脚本分析。但相比 AST 和 LSP 方法，tag 方法粒度较粗，不易获得完整调用图。
图形可视化与架构图生成：
Graphviz/pyGraphviz： 老牌的图论可视化工具，适合根据函数调用关系或模块依赖关系绘制节点-边图。通过定义 DOT 语言描述的有向图，可以生成函数调用关系图、模块依赖图等。适合后端生成静态图像。
Mermaid： 一种嵌入式的图表描述语言，支持流程图、类图、层次图等多种可视化。Mermaid 特别适合在网页前端渲染，可将后台生成的关系数据转换为 Mermaid 语法文本，由前端实时绘制图表。DeepWiki 开源项目前端即使用 Mermaid 渲染代码关系图
github.com
。优点是集成在网页方便交互、高亮。
D3.js / Cytoscape.js： 强大的前端可视化库，可用于动态展示依赖关系图谱。比如构建交互式的力导向图显示模块依赖关系、调用网络图，支持缩放、点击节点查看详情等。相对而言，D3 定制灵活但实现复杂；而 Cytoscape.js 专注于网络图展示，提供现成的布局和交互。
PlantUML： 用简单的文本描述生成UML图（类图、时序图等）。可用于表示类之间的关系或模块架构图。后端可生成图片或在前端集成实时渲染（通过PlantUML服务器或Javascript库）。
现成代码可视化工具： 一些专用工具可供参考或集成，例如 CodeAtlas（代码地图）、Codesee 等可视化平台。这些工具往往将代码按照文件结构、体量等生成可视地图。例如 CodeAtlas 的可视化基于文件字节大小，并叠加提交频率和语言构成等信息
news.ycombinator.com
（偏重整体轮廓而非函数调用）。如果关注架构层次，这类工具可提供灵感，但需要结合我们的具体分析结果定制图表。
自然语言问答与检索式 AI：
大型语言模型（LLM）： 代码问答的核心是利用具备代码理解能力的 LLM。如 OpenAI 的 GPT-3.5/GPT-4、Google 的 PaLM/Gemini 系列，或开源的 Code Llama、StarCoder 等。为了准确回答关于特定代码库的问题，LLM 需要结合代码上下文。DeepWiki 使用了针对代码和架构理解微调的模型来生成解释和回答问题
medium.com
。我们可以选择通过 API 使用云端模型（如 OpenAI API）或者部署本地模型（如 LLaMA 2 系列，可能借助 transformers 或 Ollama 等运行环境
github.com
）。
Retrieval-Augmented Generation (RAG)： 检索增强生成，即在回答前先基于问题检索相关的代码片段或文档片段供模型参考。这通常需要向量数据库和文本嵌入技术。典型流程是：对仓库中的代码文件、函数文档等生成向量嵌入索引，然后对于用户问题计算其向量，与索引近似匹配以找出相关片段，将这些片段与问题一并喂给LLM产生回答
medium.com
。
向量数据库: 开源的有 FAISS、Milvus、Chroma 等。FAISS由Facebook开源，支持高效相似度搜索，DeepWiki 类似系统中已有使用案例；例如 CodeDocs 项目采用 FAISS 来存储代码嵌入，实现代码片段的语义检索
medium.com
。Milvus则提供分布式向量存储，适合大规模数据。Chroma是新兴的嵌入存储库，易于与Python集成。
嵌入模型: 可使用OpenAI的 text-embedding-ada-002 等API获取高维向量，也可用开源模型（如 SentenceTransformers 提供的编码器）生成嵌入。针对代码，还可以使用专门的编码器如 CodeBERT、GraphCodeBERT 等提升对代码语义的捕捉。
问答链框架: 构建问答系统可以手动编排，也可使用现有框架如 LangChain 或 LlamaIndex。这些框架提供了将 LLM 与检索库连接的简便接口，可以轻松地实现“问题 -> 检索 -> LLM生成”的流水线。LangChain 还能管理提示模板、对话历史等，使问答更加智能和可控。利用这些框架，我们可以快速搭建出“阅读仓库并回答问题”的功能模块。
辅助匹配和知识库： 除了向量检索，辅助使用关键词搜索（例如用 [Symbol] 查找函数定义）也可作为补充，以确保重要的定义或注释不会被遗漏。可以将检索结果与函数的注释、README文档内容结合，一同提供给 LLM。知识图谱也是潜在方向：将代码元素及其关系存入图数据库（如Neo4j），允许通过图查询（如“哪些模块调用了类X？”）获取答案，再转化为自然语言。但实现复杂度较高，在早期可用向量检索+LLM问答实现主要功能。
技术栈建议
综合上述工具，建议采用Python 语言为主导的后端结合前端网页应用的技术栈，以充分利用丰富的代码解析库和机器学习生态，同时提供良好的用户交互界面。下表对各主要模块的技术栈选择进行汇总：
模块	建议技术选型	说明与理由
后端框架	Python + FastAPI / Flask	Python 便于调用解析库和机器学习模型；FastAPI 性能优异且易于编写 API，已在 DeepWiki 开源实现中采用
github.com
。
代码解析	Python AST/静态分析库；Tree-sitter；LSP	后端通过 Python 调用各语言解析库。对Python/JavaScript等可直接用AST库；多语言支持则嵌入 Tree-sitter 或通过调用语言服务器获取信息。可封装统一“解析服务”模块。
文档生成	OpenAI GPT-4 或 Code Llama 等 LLM；LangChain	调用强大的代码理解 LLM 来生成文字说明。通过 LangChain 等将检索到的代码片段放入 Prompt，上下文结合提问生成解答
medium.com
medium.com
。可考虑对模型进行一定领域微调以提高准确性。
向量数据库	FAISS / Chroma （内嵌库）或 Milvus（服务）	小型项目可直接使用 FAISS 在内存/本地实现嵌入检索
medium.com
。大规模或需要持久化时，可部署 Milvus 服务或使用 Chroma 等更高级方案。
图形可视化	Mermaid 前端渲染；Graphviz 后端生成	后端利用分析数据生成 Mermaid 描述文本（如架构图、调用图），前端用 Mermaid.js 动态展示
github.com
。对于复杂大型图，也可后端用 Graphviz 生成静态图像（SVG/PNG）供前端展示。
前端框架	React + Next.js / Vue.js	单页应用框架用于实现交互式界面。Next.js（React）已在 DeepWiki 前端使用
github.com
，利于实现路由、动态加载模块文档、嵌入图表组件等。Vue 亦可胜任，视团队熟悉度选择。
数据存储	文件系统 + SQLite / 图数据库（可选）	解析所得结构和生成的文档初期可直接存文件（如 Markdown 或 JSON）。如需查询，可用SQLite存储摘要和关系。对复杂依赖关系，可选用Neo4j等图数据库保存调用/依赖关系，方便执行关系查询。但图数据库引入增加系统复杂度，可视需要采用。
其他	Git 客户端、调度任务队列	使用 Git 命令或库（如 GitPython）来克隆仓库代码。若分析大型仓库耗时长，可引入任务队列（如 Celery）异步执行分析和文档生成，并通过前端轮询或WebSocket通知进度。
**注：**上述技术栈旨在平衡开发效率与功能需求。Python 生态提供了开源的解析与AI库，使我们能较快实现主要功能。同时基于Web的前后端架构，用户无需安装插件，只要提供仓库地址即可获取文档和问答功能，使用体验上类似 DeepWiki “零门槛”访问的模式
medium.com
。此外，需注意模型API密钥管理、安全性（避免执行不可信代码）等工程细节。
类似项目与参考案例
在实现本项目时，可借鉴多个已有的工具和项目经验：
DeepWiki (Devin AI): 这是最直接的参考案例。DeepWiki 能将任意Git仓库生成交互式的维基文档，包括项目简介、技术栈识别、模块/文件级解释、自动架构图、依赖关系图，以及自然语言聊天问答功能
medium.com
apidog.com
。使用上，DeepWiki通过解析代码、配置和文档，提取关键组件及其关系，并利用 AI 模型生成浅显易懂的解释
apidog.com
。其背后采用DeepResearch智能体（一个经过代码知识微调的LLM）来回答诸如“用户认证在哪实现？”之类的问题
medium.com
。DeepWiki 的技术实现包括：克隆并分析仓库结构、建立代码片段的向量索引以支持语义检索、用上下文感知的语言模型生成文档内容、绘制模块交互和数据流的图表，并提供一个交互式Web界面
medium.com
github.com
。值得注意的是，DeepWiki 通过将 GitHub URL 换成 deepwiki.com 即可访问分析结果，说明其系统针对每个仓库生成的文档是预渲染并缓存的，以支持大规模的按需查询（官方宣称已索引超过3万仓库，分析了40亿行代码
apidog.com
）。DeepWiki 开源版本（AsyncFuncAI/deepwiki-open）提供了一个自托管实现，可参考其项目结构和用到的技术
github.com
。
CodeAtlas: CodeAtlas 专注于代码库的可视化导航，提供一种“代码地图”的概念。根据开发者在 Hacker News 的介绍，Codeatlas 的可视化基于仓库中各文件的体积大小构建空间布局，并且可以叠加诸如提交密度、语言分布等信息
news.ycombinator.com
。它旨在加速对复杂代码库的熟悉，提供一个一目了然的鸟瞰图。虽然 CodeAtlas 更强调文件/模块层面的关系而非具体函数调用，但它展示了如何通过可视化帮助理解代码结构。其尚未公开按需可视化服务，但提供了示例图库供参考。从 CodeAtlas 我们可以借鉴文件树映射的思路：比如用矩形树图或节点聚类图展示各子模块大小，颜色代表语言等。我们也可考虑结合依赖关系在图上直观呈现（例如以力导向图显示模块依赖）。
CodeDocs: CodeDocs 是一项个人开发的自动化代码文档系统，可视为本项目中“代码解释生成”功能的一个简化子集。根据作者介绍，CodeDocs 接收一段代码，利用 LLM 生成 JSON 格式的文档，包括函数总结、缺失的文档注释以及改进建议，甚至还能用故事的形式讲述代码如何工作
medium.com
。其背后用到了 Google 的 Gemini-2.0-Flash 模型，并结合 FAISS 向量数据库实现检索增强 (RAG)
medium.com
。具体过程是：将用户提交的代码片段编码成向量并存入FAISS；如果启用增强，会检索相似代码片段作为参考；然后构建提示，调用 Gemini 模型生成解释，最后输出JSON或故事格式
medium.com
。这个项目体现了如何将LLM与向量检索结合来产出高质量、结构化的代码说明。借鉴意义在于，我们可以类似地对完整仓库的代码分片建立向量索引，在问答或文档生成时检索相关片段给予模型参考，从而提高回答的准确性和针对性。
GitHub Copilot Chat: Copilot Chat 是 GitHub 提供的 IDE 集成式助手，能够接受自然语言提问并对当前项目提供帮助。典型功能包括解释选中的代码片段、生成单元测试、建议代码改进，回答与代码相关的问题等
docs.github.com
。Copilot Chat背后的模型是 OpenAI 的Codex/GPT，并针对编程场景优化。它在IDE中可以获取当前打开的文件或相关上下文，从而结合提示回答问题。对于我们的项目，Copilot Chat证明了交互式代码问答的价值——开发者可以直接询问“这个函数的作用是什么？”、“如何优化这段代码？”等获得即时答案。这启发我们前端设计可加入对话界面或文本高亮提问功能，让用户在浏览生成文档时选中内容即可提问（DeepWiki 已支持选中代码提问
apidog.com
）。尽管 Copilot Chat 本身非开源，但其理念是用强大的云端LLM结合IDE上下文。我们可以在本系统中用本地解析+向量检索来模拟“上下文”，使问答更贴近用户需要。
ChatGPT Code Interpreter（Advanced Data Analysis）： OpenAI 的 Code Interpreter 是 ChatGPT的一种工具模式，可在沙盒中执行Python代码、读取上传的文件等，被广泛用于数据分析和代码处理。有开发者利用它实现对完整Git仓库的探索：将整个仓库打包连同定制提示，通过Code Interpreter加载，让ChatGPT代理在隔离环境中浏览代码、甚至编辑并提交改动
reddit.com
。例如开源项目 AgentGrunt 就采用此思路，让GPT-4 Code Interpreter自动打开仓库、回答问题、并可按需求做批量修改。这个案例展示了动态分析的前景：模型不仅静态阅读代码，还能运行测试或执行片段来辅助回答（如询问某函数输出，对应地实际调用函数）。不过，引入执行能力会增加系统复杂性和安全风险（需防范恶意代码）。在初始版本中，我们可以主要采取静态分析+LLM的方案；但参考 Code Interpreter 的理念，未来可以集成安全的代码执行沙盒，用于用户提问某些需要运行验证的问题（类似Jupyter Notebook形式的交互）。例如用户问“这个函数对输入X返回什么？”时，我们可让系统尝试运行该函数（在沙盒中）来获得答案。
类似项目小结： DeepWiki 提供了完整的功能蓝本，包括从解析、文档、图谱到问答的全套流程；CodeAtlas/CodeSee 强调了视觉概览的重要性；CodeDocs 则验证了LLM结合检索生成高质量文档的效果；Copilot Chat 和 Code Interpreter 代表了交互式、智能辅助的方向。综合它们的经验可以指导我们的系统在实现时注意：①分步处理：先静态提取结构再AI生成内容，避免一股脑大段代码提交模型。②缓存和增量更新：仓库分析结果应缓存，当代码更新时部分增量更新，而不用每次全量重新分析。③交互体验：文档浏览与提问应无缝结合，让用户随点随问，降低理解门槛。④模型局限：尽管AI强大，但对非常复杂的业务逻辑可能解释不准确，需在UI上提示生成内容可能不完美，并允许用户查看源码引用。
系统架构设计建议
针对DeepWiki类系统，应设计一套模块化分层架构，将代码解析、数据处理、文档生成、问答功能和前端展示解耦，便于扩展和维护。以下是推荐的架构分层及模块职责：
**1. 仓库获取层（Repo Ingestion）：**负责克隆或获取指定代码仓库内容。可以封装 Git 接口，支持GitHub/GitLab等来源以及私有仓库的访问令牌。【流程】用户提供仓库URL后，系统后台拉取代码。如果仓库很大，可考虑只拉取主要分支或特定目录。获取层将代码提供给后续解析层。 (在DeepWiki-Open中，这一步通过用户粘贴仓库地址或选择私有token后触发克隆
github.com
。)
2. 代码解析与关系提取层（Code Analyzer）：解析仓库源码，提取结构化信息。例如：构建文件树表示项目结构；分析模块依赖（例如导入关系、包依赖）；提取函数/方法调用图，以及类的继承/实现关系等。这个层面可进一步细分：
文件/模块层解析： 遍历仓库文件，对于每个源代码文件获取其依赖（如import或include的模块）、提供的模块名等。结果可以形成模块依赖图和文件树结构。
代码元素解析： 使用AST或LSP提取每个文件内的类和函数定义，以及函数内部的调用关系。以此构建调用图(call graph)：节点为函数，边表示调用关系；类图：节点为类，边表示继承或使用关系。
解析层产出一系列结构化数据，例如：project_structure.json（文件树/模块清单）、call_graph.json、class_hierarchy.json 等。这些数据既用于后续文档生成，也可用于直接绘制架构图。【实现】可参考前文所述开源工具组合：对于多语言项目，优先尝试 Tree-sitter 统一解析或使用对应语言的LSP。如果初期聚焦某一语言（如Python），则直接用AST配合NetworkX等构建调用图
stackoverflow.com
stackoverflow.com
。解析过程中注意处理依赖解析的作用域（如仅内部调用或跨模块调用）和边界（例如排除第三方库调用或内置API，以减小图的复杂度）。
**3. 文档内容生成层（Documentation Generator）：**利用AI模型，根据解析层的数据和源码内容生成自然语言的说明文档。可以按照项目结构分级生成：
项目总体概述： 汇总仓库README、主要模块信息，生成项目简介和技术栈说明
medium.com
。这部分可通过模板+LLM总结实现。例如读取README内容，让模型总结项目目的和主要功能
medium.com
；扫描依赖文件（如 package.json, requirements.txt）识别关键框架/库
medium.com
。
模块/目录文档： 针对每个子模块或重要目录，生成该部分代码的概述，说明其职责、包含哪些子组件、与其他模块关系等。模型需要参考模块下的文件列表、调用关系，以产生正确的描述。例如：“auth 模块包含用户认证相关的函数和配置，并被main.py调用用于登录流程”。可以为每个模块生成 markdown 文档页面，包含子模块列表、关键类函数说明、可能还有模块间交互图。
源码文件文档： 对每个源码文件，生成详细说明。包括文件作用、其中定义的类和函数列表，每个的作用简述。如果已有docstring，可引用或提炼；没有的话，让模型根据函数代码生成简短说明。同时可以列出“此函数被调用处”、“此类由哪些模块引用”等信息，从解析层数据获取。【注意】为了准确性，可以分段处理一个文件——逐个函数生成注释，再综合成文件文档。也可以采用Retrieval QA模式：对每个函数提问模型“这段代码的作用？”并根据代码内容和上下文让模型回答
medium.com
。
架构图生成： 文档层还应结合解析数据生成架构和关系图示。比如针对项目整体生成模块依赖关系图、核心调用流程图；对某模块生成该模块内类关系图等。这可以通过组装 Mermaid 文本在文档中嵌入，或提供链接点击查看放大图表。
文档生成需要精心设计提示(prompt)。例如对函数说明的提示模板可以是：「你是资深开发助手，请根据以下代码回答它的功能。代码: ...」。也可让模型输出结构化格式（如 JSON/YAML）再由程序渲染为markdown段落。DeepWiki 官方提到其使用了“知识总结引擎”将大量代码和元数据提炼为清晰解释
medium.com
。这实际就是这一层的职责，我们可以迭代打磨提示，甚至对模型做领域微调来提高文档准确度。
4. 问答模块（QA Assistant）：提供交互式的自然语言问答功能，允许用户就仓库提问。该模块可以看作一个RAG（检索增强生成）流水线：
用户问题 -> 检索相关内容 -> 构造提示并由LLM生成回答 -> 返回答案引用相关代码。
具体实现是：预先将文档内容和源码片段向量化存入索引。当用户询问时，提取问题中的关键字（或直接用向量搜索），找到最相关的代码段或文档段落
medium.com
。将检索结果与问题一起送入语言模型，让其根据这些“知识”回答。回答时可以让模型引用代码或文件名，以增加可信度（DeepWiki 回答会引用源码片段作为依据）。
此外，可实现对话模式，保持多轮上下文。用户可以继续追问细节，模型需结合之前的问题和代码上下文。可使用LangChain的 ConversationRetrievalChain 等组件简化状态管理。问答模块也应有一定的约束：当答案不确定时，让模型明示可能不准确或引导用户查看相关代码。对于超出项目范围的问题（如要求设计新功能），可以提示不在知识范围内。
提示优化： 可以引入显式的提示，例如在每次回答前加上“你只能依据给定代码回答，不要编造未给定的信息”等，以减少幻觉。DeepWiki 的实现可能通过在回答引用来源代码
news.ycombinator.com
确保答案可追溯。我们也可要求模型在答案中附上引用（这可通过在提示中示范答案格式来实现）。
性能考虑： 对大型仓库，向量索引可能很大。需限制每次检索段落数量和长度，确保提示在模型上下文长度内。同时可对常问问题（如“主函数在哪”)做些缓存。
**5. 前端展示与交互层（Frontend & UI）：**负责将上述内容友好地呈现给用户，并处理交互。前端主要功能包括：项目文档浏览、架构图查看、搜索和问答交互。设计上可类比 GitHub+Wiki 的界面：
导航： 左侧是文件树或模块列表，用户可以展开查看各模块、文件的文档页面。
文档页面： 右侧主区域显示选中的内容说明，采用Markdown渲染文本。文档中嵌入的Mermaid图可以由前端JS渲染成图形。对于源码引用，可以加上<pre>或高亮格式。
架构图视图： 提供查看全局架构的入口，比如一个“系统架构图”按钮，点击弹出对话框显示整体模块依赖图，用户可拖动缩放。复杂图考虑使用专门的JS库如 D3 来增强交互。
问答交互： 页面底部或侧边提供一个对话面板，用户可以输入问题。也支持在文档页面选中一段文字或代码，弹出“询问关于此的AI”按钮
apidog.com
。提问提交后，前端调用后端QA接口获取回答并展示。答案中如果有代码引用，前端也应渲染格式；如果有文件路径引用，最好做成可点击跳转对应文档的位置。
多轮对话与上下文： 前端可以在对话面板中展示历史问答，允许用户继续提问。对于每次提问，如果其引用了之前回答，前端可将之前回答的引用内容一并发送（或后端自己处理上下文逻辑）。但要防止无关对话无限延续，以免干扰检索准确性。
*用户输入辅助: * 提供搜索框用于关键字搜索仓库内容（可直接搜索我们生成的文档文本）；对于问答问题，可以给出一些示例问题引导用户提问（例如“📌 这个项目的主要组件有哪些？”、“📌 是否有处理数据库的模块？”等）。
前端技术如前述建议，可采用React/Next.js构建组件。DeepWiki-Open 中前端正是Next.js应用，包含文件树、Mermaid图组件等
github.com
。在UI细节上，应尽量做到简洁和响应迅速：例如文档页面初次加载可先显示大纲，问答可以采用流式输出（让模型回答过程中逐步显示文字）。良好的前端体验将大大提升工具的实用性。
**6. 缓存与更新机制：**由于完整仓库分析和文档生成可能较耗时，需设计缓存策略。**初次生成：**当用户首次请求某仓库时，后端执行上述1-4步骤生成wiki文档和索引，并将结果缓存在服务器（文件或数据库）
github.com
。**后续访问：**如果请求相同仓库且仓库未更新，可直接加载缓存文档，问答直接使用已有索引，加速响应。**仓库更新：**可提供手动刷新功能或定期检测Git仓库更新（比如根据Git commit hash判断），在变化时触发增量更新分析。缓存也应有失效策略，以平衡存储占用和新鲜度。DeepWiki 的自托管版本将嵌入和wiki内容缓存于 ~/.adalflow 目录下以便重用
github.com
。
**7. 深度分析和扩展功能：**在基本功能实现后，可考虑附加的高级功能模块：
Deep Research模式： 提供更深入的代码分析，例如扫描潜在漏洞、性能热点，或跨仓库对比。这可能需要结合静态分析工具（如CodeQL、安全lint）和额外的AI判断
medium.com
。DeepWiki 的“Deep Research”据称可以提出架构优化建议、检测代码异味等
medium.com
，实现上可能是预先定义一些检查任务，然后用LLM总结结果。我们也可设计一些规则，比如检测循环复杂度高的函数、可能的重复代码等，让AI给出“高级报告”。
定制问答: 允许用户在对话中执行特定操作，如“列出所有调用X函数的地方”，我们可以直接查询解析层的数据返回结果，而非交给AI推理（这保证准确）。通过识别问句意图，选择由规则处理还是AI处理，实现符号查询与AI推理的结合，提高准确性和效率。
多语言支持: 前端提供UI切换，可输出中文或英文文档，这需要在提示模板和生成风格上作区分。对于模型，若支持多语言输出，可以在Prompt中指定回答语言。
模块交互流程图
系统各模块可按以下流程协同工作（从用户输入到获取文档和问答的整体过程）： 
github.com
github.com
示意了 DeepWiki 从用户输入仓库到生成Wiki的流程图：
用户输入仓库地址（支持附加凭证用于私有库）
github.com
；
后端拉取代码并进行结构分析，提取代码关系
github.com
；
为代码生成向量嵌入索引，准备语义检索
github.com
；
选择LLM提供商/模型（可配置使用OpenAI、Gemini或本地模型等）
github.com
；
调用模型，对各部分代码生成解释性内容
github.com
；
解析数据用于绘制架构和关系图（Mermaid等方式）
github.com
；
将所有生成内容组织为Wiki文档结构，通过前端呈现交互界面
github.com
；
用户可浏览文档或提出问题，由问答模块检索代码内容并借助LLM回答。
(以上流程参考了 DeepWiki 开源项目 README 中提供的流程图和描述，将其文字化。)
关键功能示例代码
下面给出部分关键功能的示例代码片段，展示如何实现函数依赖解析和问答系统集成等核心能力。
1. 提取函数调用依赖关系（Python AST 示例）
以 Python 代码为例，可以使用内置 ast 模块结合 NetworkX 来构建函数调用图。以下代码解析给定的 Python 源文件，找到函数定义和它们内部的函数调用关系，用有向图表示（节点为函数名，边表示调用）：
import ast, networkx as nx

source_code = open("example.py", "r").read()
tree = ast.parse(source_code)       # 将源码解析为AST
G = nx.DiGraph()                    # 使用NetworkX构建有向图

# 第一次遍历AST，收集所有函数定义节点
func_defs = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
for func in func_defs:
    G.add_node(func.name)           # 将函数名作为图节点

# 第二次遍历，每个函数内部查找调用
for func in func_defs:
    for node in ast.walk(func):
        # 检查是否是函数调用且调用目标是名称（忽略方法属性等复杂情况）
        if isinstance(node, ast.Call) and isinstance(node.func, ast.Name):
            caller = func.name
            callee = node.func.id   # 被调用函数名称
            if callee in G.nodes:   # 只记录内部调用（在图节点列表里的）
                G.add_edge(caller, callee)

# 输出或保存调用关系图，例如打印所有调用边
print("Function call dependencies:", list(G.edges()))
上述代码假定源文件中只有函数（无类），演示了利用 AST 获取调用依赖的基本方法。【实现说明】首先收集 FunctionDef 节点建立函数列表，然后遍历每个函数定义下的所有节点，找到调用 (ast.Call) 节点，如果其调用目标是简单名称（ast.Name），则记录一条调用边。我们使用 NetworkX 的有向图存储关系，方便后续绘制或查询。对于更复杂的场景（如方法调用、类方法、模块间调用），需扩展判断逻辑，例如处理 ast.Attribute (如 obj.method() 的情况) 和跨文件关系（结合import解析解析出完整的被调函数定位）。 **验证：**假设 example.py 内容为:
def g(x): 
    return h(x)
def h(x):
    return x*7
def f(x):
    r = g(x)
    s = h(r)
    return s
运行上述解析，得到的调用边列表应类似：[('g','h'), ('f','g'), ('f','h')]，表示 f 调用了 g 和 h，而 g 调用了 h。【上述逻辑参考了Stack Overflow上对调用图生成的讨论思路【17†L136-L144】
stackoverflow.com
。】 我们可以根据解析结果构造模块依赖图或生成 Mermaid 描述。例如，将上述调用关系翻译为 Mermaid 流程图：
graph LR
    f --> g
    f --> h
    g --> h
前端渲染即可得到函数调用示意图。
2. 集成向量检索的问答系统（LangChain + FAISS 示例）
下面演示如何将向量数据库和LLM组合，实现“基于代码内容的问答”。此示例使用LangChain库和OpenAI接口：
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# 假设我们已有一系列文档片段（代码段或生成的文档）列表
documents = [
    "函数foo读取配置文件并返回配置字典...",
    "模块auth提供用户验证，包括密码校验函数verify_password...",
    # ... 更多文档片段
]

# 1. 创建嵌入索引
embedding_model = OpenAIEmbeddings(model="text-embedding-ada-002")  # 使用OpenAI嵌入模型
vector_store = FAISS.from_texts(documents, embedding_model)         # 基于文档列表创建FAISS索引
retriever = vector_store.as_retriever(search_kwargs={"k": 5})       # 配置检索top5相关片段

# 2. 设置问答链（使用GPT-3.5-Turbo模型）
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever, return_source_documents=True)

# 3. 提问并获取回答
query = "verify_password 函数是做什么的？"
result = qa_chain(query)
answer_text = result["result"]                  # 答案文本
source_docs = result["source_documents"]        # 使用的参考文档片段

print("AI回答:", answer_text)
for i, doc in enumerate(source_docs):
    print(f"引用片段#{i+1}:", doc.page_content[:100], "...")
**说明：**上述代码首先将现有文档片段转为向量并建立FAISS索引，然后构造LangChain的RetrievalQA链。在提问时，LangChain会自动从索引中检索相关的内容片段，连同问题一起传给底层ChatGPT模型，得到基于内容的回答。我们还启用了return_source_documents以获取模型参考了哪些片段
medium.com
。实际系统中，我们可以将documents初始化为仓库各模块/函数的说明和源码片段集合，以确保问答有足够知识。【CodeDocs 项目即是类似做法：将代码片段嵌入存储，再在生成解释时检索相关片段丰富Prompt【8†L75-L83】。】 当用户在前端提问时，我们调用类似上述流程的后端接口得到回答。前端可将 answer_text 展示，并根据 source_docs 高亮相关源代码或给出链接。这种方式确保AI的回答“有据可依”，提升准确性
medium.com
。例如，如果用户提问“这个函数的复杂度是多少？”，系统会检索包含该函数实现的文档片段，模型据此分析回答，并可能引用该函数实现细节。 注意：实际应用中需设置API密钥、安全控制等。若不使用OpenAI云服务，也可以将 ChatOpenAI 换成本地模型接口，比如使用 HuggingFace 提供的对话模型。DeepWiki-Open 支持切换多种模型提供商就是通过类似的封装实现的
github.com
。
综上所述，搭建一个 DeepWiki 式的系统需要综合运用代码解析、图谱可视化和AI问答技术。借助开源工具，我们能够解析出代码库的结构关系，用可视化方式呈现架构全貌，并利用大模型生成文档和回答问题，实现从代码到知识的转化。在技术栈选择上，Python 结合前后端分离框架可以高效地整合这些功能点。同时应充分参考已有项目的经验，例如 DeepWiki 对大规模仓库的支持、CodeDocs 在文档生成上的结构化输出、Copilot Chat 的人机交互细节等。在架构设计中遵循模块化原则，将解析、生成、检索、前端解耦，使系统易于扩展维护。希望本报告的调研和建议能为实现这一系统提供有力的参考，使之最终成为开发者高效获取代码知识的利器。
medium.com
medium.com
github.com
